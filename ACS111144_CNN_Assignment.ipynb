{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHY5PuaMy-8h"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxbedAx6L8Nb",
        "outputId": "de4fb0bf-d677-4ee3-f875-95711bff558f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "--- 訓練分類頭 ---\n",
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 18ms/step - accuracy: 0.6151 - loss: 1.1363 - val_accuracy: 0.7543 - val_loss: 0.6970 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 9ms/step - accuracy: 0.7363 - loss: 0.7702 - val_accuracy: 0.7710 - val_loss: 0.6529 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.7555 - loss: 0.7104 - val_accuracy: 0.7756 - val_loss: 0.6458 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7674 - loss: 0.6758 - val_accuracy: 0.7900 - val_loss: 0.6170 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.7781 - loss: 0.6373 - val_accuracy: 0.7940 - val_loss: 0.6026 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.7877 - loss: 0.6079 - val_accuracy: 0.7867 - val_loss: 0.6231 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.7956 - loss: 0.5926 - val_accuracy: 0.7971 - val_loss: 0.6076 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 0.5085 - val_accuracy: 0.8083 - val_loss: 0.5699 - learning_rate: 2.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.8330 - loss: 0.4775 - val_accuracy: 0.8110 - val_loss: 0.5664 - learning_rate: 2.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.8390 - loss: 0.4655 - val_accuracy: 0.8114 - val_loss: 0.5689 - learning_rate: 2.0000e-04\n",
            "313/313 - 2s - 7ms/step - accuracy: 0.8110 - loss: 0.5664\n",
            "\n",
            "Model Performance Summary:\n",
            "  Test Accuracy: 0.8110\n",
            "  Test Loss: 0.5664\n",
            "  Final Training Accuracy: 0.8371\n",
            "  Final Validation Accuracy: 0.8114\n",
            "  Final Training Loss: 0.4640\n",
            "  Final Validation Loss: 0.5689\n",
            "  Training Epochs: 10\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, callbacks, applications\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Step 2: Load and Preprocess CIFAR-10 Dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define class names for visualization\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Step 3: 建立模型 - 遷移學習\n",
        "# 載入預訓練的 MobileNetV2 模型，不包含頂部的分類層\n",
        "# weights='imagenet' -> 使用在 ImageNet 上訓練好的權重\n",
        "# input_shape -> 我們影像的尺寸\n",
        "# include_top=False -> 我們要自己定義分類層\n",
        "base_model = applications.MobileNetV2(\n",
        "    input_shape=(96, 96, 3), # Corrected input shape to match the upsampled image\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# 凍結預訓練模型的權重，在第一階段訓練時我們不去動它\n",
        "base_model.trainable = False\n",
        "\n",
        "# 建立我們自己的模型\n",
        "# 我們需要將 32x32 的影像放大，因為 MobileNetV2 在較大影像上表現更好\n",
        "# 這裡我們將其放大到 96x96\n",
        "inputs = layers.Input(shape=(32, 32, 3))\n",
        "x = layers.UpSampling2D(size=(3,3))(inputs) # 放大影像\n",
        "x = base_model(x, training=False) # 確保 base_model 在推論模式\n",
        "x = layers.GlobalAveragePooling2D()(x) # 將特徵圖轉換為向量\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x) # 加入 Dropout 防止過擬合\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "# 顯示模型摘要 (只會顯示我們自己加的層和總參數)\n",
        "# model.summary() # This is commented out as the original did not print it twice before the final summary.\n",
        "\n",
        "\n",
        "# Step 4: 編譯模型 (第一階段)\n",
        "# 使用較高的學習率來訓練我們新加的分類層\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 5: 定義回呼函式 (Callbacks)\n",
        "# 除了 EarlyStopping，我們再加入學習率動態調整\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=6, # 耐心設短一點，因為我們有兩個訓練階段\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2, # 當學習停滯時，將學習率乘以 0.2\n",
        "    patience=2,\n",
        "    min_lr=0.00001 # 學習率最小不低於此值\n",
        ")\n",
        "\n",
        "# Step 6: 訓練模型 (第一階段 - 只訓練分類頭)\n",
        "print(\"--- 訓練分類頭 ---\")\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    epochs=12, # 第一階段不需要太多 epochs\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "\n",
        "# Step 7: Evaluate and Print Performance Summary\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "\n",
        "final_train_acc = history.history['accuracy'][-1]\n",
        "final_val_acc = history.history['val_accuracy'][-1]\n",
        "final_train_loss = history.history['loss'][-1]\n",
        "final_val_loss = history.history['val_loss'][-1]\n",
        "training_epochs = len(history.history['accuracy'])\n",
        "\n",
        "print(\"\\nModel Performance Summary:\")\n",
        "print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "print(f\"  Final Training Accuracy: {final_train_acc:.4f}\")\n",
        "print(f\"  Final Validation Accuracy: {final_val_acc:.4f}\")\n",
        "print(f\"  Final Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"  Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"  Training Epochs: {training_epochs}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
