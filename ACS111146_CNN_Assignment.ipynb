{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3t1TFdQk4yL",
        "outputId": "8d8717ce-3196-4bc7-e4c5-28e9051842a6",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Step 1: Import Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Record start time for performance measurement\n",
        "start_time = time.time()\n",
        "\n",
        "# Step 2: Load and Preprocess CIFAR-10 Dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "train_images, test_images = train_images.astype('float32') / 255.0, test_images.astype('float32') / 255.0\n",
        "\n",
        "# Define class names for visualization\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Step 3: Build the Advanced CNN Model\n",
        "# This model is deeper and includes Batch Normalization and Dropout for better performance.\n",
        "model = models.Sequential([\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Dropout(0.4),\n",
        "\n",
        "    # Flatten the output and feed it into dense layers\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    # Output Layer\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Step 4: Compile the Model\n",
        "# Using Adam optimizer, a standard choice.\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Set up Data Augmentation and Callbacks\n",
        "# Data Augmentation to prevent overfitting\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# Callbacks for advanced training control\n",
        "# EarlyStopping to stop training when the model is not improving and restore best weights\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "# ReduceLROnPlateau to reduce learning rate when validation loss plateaus\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "# Step 6: Train the Model\n",
        "# We train for more epochs, but EarlyStopping will find the optimal point.\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[early_stopping, reduce_lr],\n",
        "                    verbose=1)\n",
        "\n",
        "# Record end time\n",
        "end_time = time.time()\n",
        "training_duration = end_time - start_time\n",
        "print(f\"\\nTotal training duration: {training_duration / 60:.2f} minutes\")\n",
        "\n",
        "# Step 7: Evaluate the Model\n",
        "# Thanks to restore_best_weights=True, the model already has the weights from the epoch with the best val_loss.\n",
        "print(\"\\nEvaluating the best model...\")\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"‚úÖ Final Test Accuracy (from best model): {test_acc:.4f}\")\n",
        "\n",
        "# Step 8: Plot Training and Validation Curves\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 9: Save Model Performance for Autograding (Corrected Logic)\n",
        "try:\n",
        "    # Find the epoch with the best validation loss, which EarlyStopping used\n",
        "    best_epoch_idx = np.argmin(history.history['val_loss'])\n",
        "\n",
        "    # Get all performance metrics from that best epoch\n",
        "    best_val_loss = history.history['val_loss'][best_epoch_idx]\n",
        "    best_val_acc = history.history['val_accuracy'][best_epoch_idx]\n",
        "    best_train_loss = history.history['loss'][best_epoch_idx]\n",
        "    best_train_acc = history.history['accuracy'][best_epoch_idx]\n",
        "\n",
        "    # Create the performance summary text\n",
        "    performance_text = f\"\"\"Model Performance Summary (at best validation loss epoch):\n",
        "Total Training Duration: {training_duration / 60:.2f} minutes\n",
        "\n",
        "--- Final Evaluation on Test Set ---\n",
        "Test Accuracy: {test_acc:.4f}\n",
        "Test Loss: {test_loss:.4f}\n",
        "\n",
        "--- Metrics at Best Epoch ({best_epoch_idx + 1}) ---\n",
        "Best Validation Loss: {best_val_loss:.4f}\n",
        "Best Validation Accuracy: {best_val_acc:.4f}\n",
        "Corresponding Training Loss: {best_train_loss:.4f}\n",
        "Corresponding Training Accuracy: {best_train_acc:.4f}\n",
        "\n",
        "--- Training Details ---\n",
        "Total Training Epochs Ran: {len(history.history['accuracy'])}\n",
        "Model Parameters: {model.count_params()}\"\"\"\n",
        "\n",
        "    with open('model_accuracy.txt', 'w') as f:\n",
        "        f.write(performance_text)\n",
        "\n",
        "    print(\"\\nüìÑ Model performance saved to model_accuracy.txt\")\n",
        "    print(performance_text)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error saving model performance: {e}\")\n",
        "    with open('model_accuracy.txt', 'w') as f:\n",
        "        f.write(f\"Model execution completed with errors: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
